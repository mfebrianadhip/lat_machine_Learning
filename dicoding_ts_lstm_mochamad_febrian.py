# -*- coding: utf-8 -*-
"""dicoding_ts_lstm_Mochamad_Febrian.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jZwLpiiTs70IEXEI2umKdBiKQ99F8jqc

# Proyek Kedua Dicoding : Membuat Model Machine Learning dengan Data Time Series
**Kriteria Submission yang harus penuhi:**

- Dataset yang akan dipakai bebas, namun minimal memiliki 1000 sampel.
- Harus menggunakan LSTM dalam arsitektur model.
- Validation set sebesar 20% dari total dataset.
- Model harus menggunakan model sequential.
- Harus menggunakan Learning Rate pada Optimizer.
- MAE < 10% skala data

# Mengunduh data set pada google colab
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/Data/london_merged.csv', parse_dates=['timestamp'], index_col='timestamp')
df

df.isnull().sum()

"""# Visualisasi Dataset Timeseries"""

df['hour'] = df.index.hour
df['day_of_week']= df.index.dayofweek
df['day_of_month']= df.index.day
df['month']=df.index.month

"""- Melihat data  jumlah sepedah terjual( *the count of a new bike shares* (cnt))  terhadap waktu"""

import seaborn as sns

sns.lineplot(x=df.index, y='cnt', data=df);

import matplotlib.pyplot as plt

df_by_month = df.resample('M').sum()

time = df_by_month.index.values
test = df_by_month['cnt'].values
plt.figure(figsize=(10,5))
plt.plot(time, test)

"""# Membagi data Training dan Validasi

- Membagi data set menjadi 80% data train dan  20% data test
"""

from sklearn.model_selection import train_test_split
import numpy as np

train_size = int(len(df)*0.8)
train, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]
print(train.shape, test.shape)

"""- Melakukan Normaliasi Data"""

from sklearn.preprocessing import RobustScaler

transformer = RobustScaler()
cnt_transformer = transformer.fit(train[['cnt']])

train['cnt'] = cnt_transformer.transform(train[['cnt']])

test['cnt'] = cnt_transformer.transform(test[['cnt']])

scale_col = ['t1', 't2', 'hum', 'wind_speed']
scale_transformer = transformer.fit(train[scale_col].to_numpy())

train.loc[:, scale_col] = scale_transformer.transform(
    train[scale_col].to_numpy()
)

test.loc[:, scale_col] = scale_transformer.transform(
    test[scale_col].to_numpy()
)

"""- Melakukan Spliting Data"""

import numpy as np
import tensorflow as tf

def split_data(x, y, time_steps=1):
    xs, ys = [], []
    for i in range(len(x) - time_steps):
        v = x.iloc[i:(i + time_steps)].values
        xs.append(v)
        ys.append(y.iloc[i + time_steps])
    return np.array(xs), np.array(ys)

x_train, y_train = split_data(train, train.cnt, 10)
x_test, y_test = split_data(test, test.cnt, 10)

print(x_train.shape, y_train.shape)

"""# Membuat dan Melatih Model

- Membuat Model Sequential dengan Arsitektur LSTM
"""

model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(128, return_sequences=True),
    tf.keras.layers.LSTM(128),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(30, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(30, activation='relu'),
    tf.keras.layers.Dense(1)])

"""- Membuat fitur Callbacks"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')< 0.1):
      print("\n MAE telah mencapai <10% dari skala data")
      self.model.stop_training = True
callbacks = myCallback()

"""- Melatih Model"""

model.compile(loss = tf.keras.losses.Huber(),
              optimizer = tf.keras.optimizers.Adam(lr=0.01),
              metrics = ["mae"])

history = model.fit(x_train,
                    y_train,
                    epochs=100,
                    batch_size=32,
                    validation_split=0.2,
                    callbacks = callbacks,
                    shuffle=False)

"""# Membuat plot model data train dan validasi"""

import matplotlib.pyplot as plt
mae = history.history['mae']
val_mae = history.history['val_mae']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(mae))

plt.figure(figsize=(14, 4))

plt.subplot(1, 2, 1)
plt.title('MAE')
plt.xlabel('Epoch')
plt.ylabel('mae')
plt.plot(mae, label='MAE Training')
plt.plot(val_mae, label='Validasi', linestyle='--')
plt.legend()

plt.subplot(1, 2, 2)
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.plot(loss, label='MAE Training')
plt.plot(val_loss, label='Validasi', linestyle='--')
plt.legend()

plt.show()

"""# Identitas Diri
- Nama : Mochamad Febrian Adhi Patria
- Peserta digitalent Scholarship 2021
- Proyek Kedua Dicoding : Membuat Model Machine Learning dengan Data Time Series
"""